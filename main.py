#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import re
import html
import asyncio
import feedparser
import openai
from telegram import Bot
import requests
from datetime import datetime, timezone
from zoneinfo import ZoneInfo
from io import BytesIO
from difflib import SequenceMatcher
from urllib.parse import urlparse

import yfinance as yf
from pycoingecko import CoinGeckoAPI
from PIL import Image  # Pillow –¥–ª—è –∞–≤—Ç–æ—Å–∂–∞—Ç–∏—è

# ================== CONFIG ==================
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
TELEGRAM_CHANNEL_RU = os.getenv("TELEGRAM_CHANNEL_RU", "-1002597393191")

# –í –ø—Ä–æ–¥–µ –≤–∫–ª—é—á–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è SEND_TO_TELEGRAM=1
SEND_TO_TELEGRAM = os.getenv("SEND_TO_TELEGRAM", "0") == "1"   # 0 = —Ç–æ–ª—å–∫–æ –∫–æ–Ω—Å–æ–ª—å, 1 = —Å–ª–∞—Ç—å –≤ TG
MAX_CAPTION = 1024  # –ª–∏–º–∏—Ç –ø–æ–¥–ø–∏—Å–∏ –∫ —Ñ–æ—Ç–æ –≤ Telegram

NEWS_COUNT = 15
SIGNATURE = "–° –≤–∞–º–∏ –±—ã–ª ReserveOne ‚òïÔ∏è"

# –¢–∞–π–º–∑–æ–Ω–∞ –∏ ¬´—É—Ç—Ä–µ–Ω–Ω–µ–µ –æ–∫–Ω–æ —Å–≤–µ–∂–µ—Å—Ç–∏¬ª
LOCAL_TZ = ZoneInfo("Europe/Vienna")
FRESHNESS_HOURS_MORNING = int(os.getenv("FRESHNESS_HOURS_MORNING", "18"))  # —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 18—á

# –ò—Å—Ç–æ—á–Ω–∏–∫ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: "last_close" (–≤—á–µ—Ä–∞ vs –ø–æ–∑–∞–≤—á–µ—Ä–∞) –∏–ª–∏ "intraday"
MARKET_SOURCE_MODE = os.getenv("MARKET_SOURCE_MODE", "last_close")  # last_close | intraday

# –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–∫–µ—à–∏—Ä—É–µ–º –∏ —É–º–µ–Ω—å—à–∞–µ–º –≤—ã—Å–æ—Ç—É)
IMAGES_DIR = "images"
os.makedirs(IMAGES_DIR, exist_ok=True)
STATIC_IMAGE_PATH = os.path.join(IMAGES_DIR, "morning_digest_static.png")
TARGET_IMAGE_HEIGHT = int(os.getenv("TARGET_IMAGE_HEIGHT", "750"))

# –ë–∞–ª–∞–Ω—Å –∫—Ä–∏–ø—Ç–æ/—Ñ–∏–Ω–∞–Ω—Å–æ–≤ (—Ä–µ–≥—É–ª–∏—Ä—É–µ—Ç—Å—è —á–µ—Ä–µ–∑ env)
CRYPTO_RATIO = float(os.getenv("CRYPTO_RATIO", "0.4"))          # —Ü–µ–ª–µ–≤–∞—è –¥–æ–ª—è –∫—Ä–∏–ø—Ç–æ –≤ –ø—É–ª–µ
MIN_FIN_NEWS = int(os.getenv("MIN_FIN_NEWS", "6"))              # –º–∏–Ω–∏–º—É–º —Ñ–∏–Ω–Ω–æ–≤–æ—Å—Ç–µ–π
CRYPTO_KEYWORD_BONUS = int(os.getenv("CRYPTO_KEYWORD_BONUS", "50"))

CRYPTO_FEEDS = [
    "https://cointelegraph.com/rss",
    "https://www.coindesk.com/arc/outboundfeeds/rss/",
    "https://decrypt.co/feed",
    "https://theblock.co/rss",
]
FINANCE_FEEDS = [
    "https://www.bloomberg.com/feed/podcast/etf-report.xml",
    "https://feeds.a.dj.com/rss/RSSMarketsMain.xml",
    "https://www.reuters.com/finance/rss",
    "https://www.marketwatch.com/rss/topstories",
    "https://www.kitco.com/rss/",
    "https://www.cnbc.com/id/15839135/device/rss/rss.html",
    "https://www.investing.com/rss/news_301.rss",
    "https://www.investing.com/rss/news_25.rss",
    "https://www.morningbrew.com/feed.xml",
]

# ================== IMAGE UTILS ==================
def static_image_exists() -> bool:
    try:
        return os.path.exists(STATIC_IMAGE_PATH) and os.path.getsize(STATIC_IMAGE_PATH) > 1024
    except Exception:
        return False

def save_static_image(image_bytes: BytesIO) -> bool:
    try:
        temp_path = STATIC_IMAGE_PATH + ".tmp"
        with open(temp_path, "wb") as f:
            f.write(image_bytes.getvalue())
        if os.path.getsize(temp_path) > 1024:
            os.replace(temp_path, STATIC_IMAGE_PATH)
            print(f"‚úÖ –°—Ç–∞—Ç–∏—á–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {STATIC_IMAGE_PATH}")
            return True
        if os.path.exists(temp_path):
            os.remove(temp_path)
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        return False

def load_static_image() -> BytesIO | None:
    try:
        if os.path.exists(STATIC_IMAGE_PATH) and os.path.getsize(STATIC_IMAGE_PATH) > 1024:
            with open(STATIC_IMAGE_PATH, "rb") as f:
                buf = BytesIO(f.read())
                buf.seek(0)
                return buf
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
    return None

def resize_image_height(image_bytes: BytesIO, target_height: int = 750) -> BytesIO:
    """
    –£–º–µ–Ω—å—à–∞–µ—Ç —Ç–æ–ª—å–∫–æ –≤—ã—Å–æ—Ç—É –¥–æ target_height, —à–∏—Ä–∏–Ω—É –æ—Å—Ç–∞–≤–ª—è–µ—Ç –∫–∞–∫ –µ—Å—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1024x1024 ‚Üí 1024x750).
    """
    try:
        img = Image.open(image_bytes)
        w, h = img.size
        if h <= target_height:
            image_bytes.seek(0)
            return image_bytes
        resized = img.resize((w, target_height), Image.Resampling.LANCZOS)
        out = BytesIO()
        resized.save(out, format="PNG")
        out.seek(0)
        return out
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤—ã—Å–æ—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        image_bytes.seek(0)
        return image_bytes

# ================== NEWS FRESHNESS/SCORING ==================
def _utcnow() -> datetime:
    return datetime.now(timezone.utc)

def _strip_tags(s: str) -> str:
    return re.sub(r"<.*?>", "", s or "").strip()

def _unescape_then_escape(s: str) -> str:
    s = html.unescape(s or "")
    s = s.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
    return s

def _norm_title(t: str) -> str:
    t = _strip_tags(t or "")
    t = re.sub(r"[\[\]\(\){}‚Äú‚Äù\"'¬´¬ª‚Ä¢¬∑\-‚Äì‚Äî:;,.!?]", " ", t)
    t = re.sub(r"\s+", " ", t).strip().lower()
    return t

def _similar(a: str, b: str) -> float:
    return SequenceMatcher(None, a, b).ratio()

def is_quality_news(title: str, summary: str) -> bool:
    text = f"{title} {summary}".lower()
    if len(title) < 10 or len(summary) < 20:
        return False
    spam = ["click here","subscribe","newsletter","advertisement","sponsored","promotion","–ø–æ–¥–ø–∏—à–∏—Ç–µ—Å—å","—Ä–µ–∫–ª–∞–º–∞"]
    if any(k in text for k in spam):
        return False
    has_numbers = bool(re.search(r"\$\s?\d[\d.,]*|\d+%|\d+\.\d+", text))
    has_event = any(w in text for w in [
        "earnings","revenue","profit","loss","ipo","merger","acquisition",
        "rate","inflation","gdp","unemployment","fed","ecb","sec",
        "bitcoin","ethereum","crypto","stock","market","–≤—ã—Ä—É—á–∫–∞","–ø—Ä–∏–±—ã–ª—å","—Å—Ç–∞–≤–∫–∞","–∏–Ω—Ñ–ª—è—Ü–∏—è","–±–∏—Ç–∫–æ–∏–Ω","–∞–∫—Ü–∏–∏"
    ])
    return has_numbers or has_event

def score_item(n: dict) -> int:
    score = 0
    text = f"{n.get('title','')} {n.get('summary','')}".lower()
    if re.search(r"\b(–±–∏—Ç–∫–æ–∏–Ω|bitcoin|btc|ethereum|eth|crypto|blockchain)\b", text):
        score += CRYPTO_KEYWORD_BONUS
    if re.search(r"\$\s?\d[\d.,]*|\d+%|\d+\.\d+", text):
        score += 40
    host = (urlparse(n.get("link") or "").hostname or "").lower()
    for src, val in {
        "bloomberg.com": 20,"reuters.com": 20,"cnbc.com": 15,"coindesk.com": 15,
        "cointelegraph.com": 12,"marketwatch.com": 10,"investing.com": 8,"morningbrew.com": 4,
    }.items():
        if src in host:
            score += val
    age = float(n.get("age_hours") or 999.0)
    score -= int(age ** 1.1)  # —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π —à—Ç—Ä–∞—Ñ –ø–æ –≤–æ–∑—Ä–∞—Å—Ç—É
    return score

def get_feed_news(feeds: list[str], max_news: int) -> list[dict]:
    entries: list[dict] = []
    now = _utcnow()

    for url in feeds:
        try:
            d = feedparser.parse(url)
            if not d.entries:
                continue
            for entry in d.entries:
                st = entry.get("published_parsed") or entry.get("updated_parsed")
                if not st:
                    continue
                published_dt = datetime(*st[:6], tzinfo=timezone.utc)
                age_hours = (now - published_dt).total_seconds() / 3600.0
                if age_hours > FRESHNESS_HOURS_MORNING:
                    continue
                title = _unescape_then_escape(_strip_tags(entry.get("title") or ""))
                summary = _unescape_then_escape(_strip_tags(entry.get("summary") or ""))
                link = (entry.get("link") or "").strip()
                if not (title or summary):
                    continue
                if not is_quality_news(title, summary):
                    continue
                item = {
                    "title": title,
                    "title_norm": _norm_title(title),
                    "summary": summary,
                    "link": link,
                    "source": url,
                    "published_dt": published_dt,
                    "age_hours": age_hours,
                }
                entries.append(item)
        except Exception as e:
            print(f"‚ö†Ô∏è Feed error ({url}): {e}")

    if not entries:
        return []

    # –¥–µ–¥—É–ø –ø–æ —Å—Å—ã–ª–∫–µ
    seen, uniq = set(), []
    for e in entries:
        lk = e.get("link") or ""
        if lk and lk not in seen:
            seen.add(lk)
            uniq.append(e)

    # –∞–Ω—Ç–∏-–¥—É–±–ª—å –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º (—Å–µ–º–∞–Ω—Ç–∏–∫–∞)
    filtered: list[dict] = []
    for e in uniq:
        if any(_similar(e["title_norm"], x["title_norm"]) > 0.92 for x in filtered):
            continue
        filtered.append(e)

    # —Å–∫–æ—Ä–∏–Ω–≥ + —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
    for n in filtered:
        n["score"] = score_item(n)
    filtered.sort(key=lambda x: (x["score"], -x["published_dt"].timestamp()), reverse=True)

    # –±–∞–ª–∞–Ω—Å –∫—Ä–∏–ø—Ç–æ/—Ñ–∏–Ω
    def is_crypto_item(it: dict) -> bool:
        t = (it.get("title","") + " " + it.get("summary","")).lower()
        return bool(re.search(r"\b(bitcoin|btc|ethereum|eth|crypto)\b", t))

    crypto_items = [n for n in filtered if is_crypto_item(n)]
    fin_items = [n for n in filtered if not is_crypto_item(n)]

    max_crypto = max(1, int(NEWS_COUNT * CRYPTO_RATIO))
    balanced = crypto_items[:max_crypto] + fin_items
    balanced.sort(key=lambda x: (x["score"], -x["published_dt"].timestamp()), reverse=True)

    return balanced[: max_news * 2]

def filter_by_importance(news_list: list[dict], take: int) -> list[dict]:
    # –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –º–∏–Ω–∏–º—É–º —Ñ–∏–Ω–Ω–æ–≤–æ—Å—Ç–µ–π
    def is_crypto_item(it: dict) -> bool:
        t = (it.get("title","") + " " + it.get("summary","")).lower()
        return bool(re.search(r"\b(bitcoin|btc|ethereum|eth|crypto)\b", t))
    crypto = [n for n in news_list if is_crypto_item(n)]
    fin = [n for n in news_list if not is_crypto_item(n)]
    out = fin[:MIN_FIN_NEWS] + crypto
    if len(out) < take:
        out += [n for n in fin[MIN_FIN_NEWS:]]  # –¥–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–Ω–æ–≤–æ—Å—Ç—è–º–∏
    return out[:take]

# ================== MARKET DATA ==================
def validate_market_data(data_type, current_value, change_percent) -> bool:
    rules = {
        "sp500": {"min": 2000, "max": 8000, "change_max": 10},
        "nasdaq": {"min": 5000, "max": 25000, "change_max": 10},
        "dxy": {"min": 80, "max": 120, "change_max": 5},
        "gold": {"min": 1000, "max": 3000, "change_max": 8},
        "oil": {"min": 20, "max": 150, "change_max": 15},
        "treasury": {"min": 0, "max": 10, "change_max": 2},
    }
    if data_type not in rules:
        return True
    r = rules[data_type]
    if not (r["min"] <= current_value <= r["max"]):
        print(f"‚ö†Ô∏è –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ {data_type}: {current_value}")
        return False
    if abs(change_percent) > r["change_max"]:
        print(f"‚ö†Ô∏è –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ {data_type}: {change_percent:.2f}%")
        return False
    return True

def _pair_last_close(df):
    # –≤—á–µ—Ä–∞—à–Ω–∏–π close vs –ø–æ–∑–∞–≤—á–µ—Ä–∞—à–Ω–∏–π ‚Äî –∏–¥–µ–∞–ª—å–Ω–æ –¥–ª—è —É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –ø–æ—Å—Ç–∞
    if df.empty or len(df) < 2:
        return None
    cur = float(df["Close"].iloc[-1])
    prev = float(df["Close"].iloc[-2])
    chg = (cur - prev) / prev * 100
    return cur, chg

def _pair_intraday(df):
    # –ø–æ—Å–ª–µ–¥–Ω–∏–π Close vs –ø—Ä–µ–¥—ã–¥—É—â–∏–π Close (–µ—Å–ª–∏ –Ω—É–∂–µ–Ω –±–æ–ª–µ–µ ¬´–æ–Ω–ª–∞–π–Ω–æ–≤—ã–π¬ª –≤–∏–¥)
    if df.empty:
        return None
    if len(df) >= 2:
        cur = float(df["Close"].iloc[-1])
        prev = float(df["Close"].iloc[-2])
    else:
        cur = float(df["Close"].iloc[-1])
        prev = cur
    chg = (cur - prev) / prev * 100 if prev else 0.0
    return cur, chg

async def get_market_data():
    try:
        print("üìä –ü–æ–ª—É—á–∞–µ–º —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...")
        sp500 = yf.download("^GSPC", period="2d", interval="1d", auto_adjust=False)
        nasdaq = yf.download("^IXIC", period="2d", interval="1d", auto_adjust=False)
        dxy = yf.download("DX-Y.NYB", period="2d", interval="1d", auto_adjust=False)
        gold = yf.download("GC=F", period="2d", interval="1d", auto_adjust=False)
        oil = yf.download("BZ=F", period="2d", interval="1d", auto_adjust=False)
        tnx = yf.download("^TNX", period="2d", interval="1d", auto_adjust=False)

        market_data = {}
        _pair = _pair_last_close if MARKET_SOURCE_MODE == "last_close" else _pair_intraday

        def _put(name, df):
            pair = _pair(df)
            if pair and validate_market_data(name, pair[0], pair[1]):
                market_data[name] = pair

        _put("sp500", sp500)
        _put("nasdaq", nasdaq)
        _put("dxy", dxy)
        _put("gold", gold)
        _put("oil", oil)
        _put("treasury", tnx)

        for k, (v, c) in market_data.items():
            unit = "$" if k in ("sp500", "nasdaq", "gold", "oil") else ""
            print(f"‚úÖ {k.upper()}: {unit}{v:.2f} ({c:+.2f}%)")

        return market_data
    except Exception as e:
        print(f"‚ùå Error fetching market data: {e}")
        return None

async def get_crypto_data():
    try:
        print("üí∞ –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç...")
        cg = CoinGeckoAPI()
        data = cg.get_price(
            ids="bitcoin,ethereum,binancecoin,ripple,solana",
            vs_currencies="usd",
            include_24hr_change=True,
        )
        if data:
            if "bitcoin" in data:
                print(f"‚úÖ BTC: ${data['bitcoin']['usd']:,.0f} ({data['bitcoin']['usd_24h_change']:+.2f}%)")
            if "ethereum" in data:
                print(f"‚úÖ ETH: ${data['ethereum']['usd']:,.0f} ({data['ethereum']['usd_24h_change']:+.2f}%)")
        return data
    except Exception as e:
        print(f"‚ùå Error fetching crypto data: {e}")
        return None

# ================== IMAGE GEN (1024x1024 ‚Üí —É–º–µ–Ω—å—à–µ–Ω–∏–µ –≤—ã—Å–æ—Ç—ã) ==================
async def get_morning_image() -> BytesIO | None:
    if not SEND_TO_TELEGRAM:
        print("üñºÔ∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–∞ (SEND_TO_TELEGRAM=0).")
        return None

    if static_image_exists():
        print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–µ —Å—Ç–∞—Ç–∏—á–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
        cached = load_static_image()
        if cached:
            return cached
        print("‚ö†Ô∏è –ö—ç—à –ø–æ–≤—Ä–µ–∂–¥—ë–Ω ‚Äî –≥–µ–Ω–µ—Ä–∏—Ä—É—é –Ω–æ–≤–æ–µ‚Ä¶")

    print("üé® –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤–æ–µ —Å—Ç–∞—Ç–∏—á–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ‚Ä¶")
    try:
        client = openai.AsyncOpenAI(api_key=OPENAI_API_KEY)
        prompt = (
            "Digital illustration, fun but professional, modern flat style, soft colors. "
            "Minimalist morning finance theme: coffee cup, newspaper icons, coins, charts. "
            "Clean lines, soft pastel palette. No text."
        )
        resp = await client.images.generate(
            model="dall-e-3",
            prompt=prompt,
            n=1,
            size="1024x1024",
        )
        img_url = resp.data[0].url
        buf = BytesIO(requests.get(img_url, timeout=20).content)

        resized = resize_image_height(buf, target_height=TARGET_IMAGE_HEIGHT)

        if save_static_image(resized):
            cached = load_static_image()
            if cached:
                return cached
        resized.seek(0)
        return resized
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        return None

# ================== DIGEST BUILD HELPERS (–ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞) ==================
def sanitize_markdown(text: str) -> str:
    """–£–±–∏—Ä–∞–µ–º **–∂–∏—Ä–Ω—ã–π**, __–ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ__ –∏ –ø—Ä–æ—á–∏–π markdown/–ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã."""
    if not text:
        return ""
    out = re.sub(r"\*\*(.*?)\*\*", r"\1", text)      # **bold**
    out = re.sub(r"__(.*?)__", r"\1", out)           # __underline__
    out = re.sub(r"_([^_]+)_", r"\1", out)           # _italic_
    out = re.sub(r"`([^`]+)`", r"\1", out)           # `code`
    out = re.sub(r"\s+\n", "\n", out)
    return out.strip()

SECTION_ORDER = ["1Ô∏è‚É£","2Ô∏è‚É£","3Ô∏è‚É£","4Ô∏è‚É£","5Ô∏è‚É£","6Ô∏è‚É£","7Ô∏è‚É£"]
SECTION_EMOJI = {"1Ô∏è‚É£":"üìä","2Ô∏è‚É£":"üìà","3Ô∏è‚É£":"üè¶","4Ô∏è‚É£":"üß≠","5Ô∏è‚É£":"üè¢","6Ô∏è‚É£":"üöÄ","7Ô∏è‚É£":"üåç"}

def enforce_seven_compact_lines(draft: str) -> str:
    """
    –ë–µ—Ä—ë–º –º–∞–∫—Å–∏–º—É–º –ø–æ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ –Ω–∞ –∫–∞–∂–¥—ã–π –ø—É–Ω–∫—Ç 1..7.
    –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ª—é–±—ã–µ —Å—Ç—Ä–æ–∫–∏, –Ω–µ –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å –Ω–æ–º–µ—Ä–∞ —Å–µ–∫—Ü–∏–∏.
    –†–µ–∂–µ–º –≤—Ç–æ—Ä—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–π —Ç–æ—á–∫–∏).
    """
    seen = set()
    picked = []
    for raw in (l.strip() for l in draft.splitlines()):
        if not raw:
            continue
        m = re.match(r"^([1-7]Ô∏è‚É£)\s*(.+)$", raw)
        if not m:
            continue
        tag, rest = m.groups()
        if tag in seen:
            continue
        one = re.split(r"(?<=\.)\s", rest, maxsplit=1)[0].strip()
        if ":" not in one:
            name = {
                "1Ô∏è‚É£":"–ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Ä—ã–Ω–∫–∏",
                "2Ô∏è‚É£":"–ò—Ç–æ–≥–∏ —Ç–æ—Ä–≥–æ–≤",
                "3Ô∏è‚É£":"–¢—Ä–µ–∂–µ—Ä–∏—Å, DXY, –∑–æ–ª–æ—Ç–æ, –Ω–µ—Ñ—Ç—å",
                "4Ô∏è‚É£":"–ú–æ–Ω–µ—Ç–∞—Ä–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞",
                "5Ô∏è‚É£":"–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏",
                "6Ô∏è‚É£":"–ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã",
                "7Ô∏è‚É£":"–ì–µ–æ–ø–æ–ª–∏—Ç–∏–∫–∞",
            }[tag]
            one = f"{name}: {one}"
        picked.append(f"{tag} {one}")
        seen.add(tag)
        if len(picked) == 7:
            break
    picked.sort(key=lambda s: SECTION_ORDER.index(s[:2]) if s[:2] in SECTION_ORDER else 99)
    return "\n\n".join(picked)

def decorate_digest_with_emojis(digest: str) -> str:
    """–≠–º–æ–¥–∑–∏ –¥–ª—è –ø—É–Ω–∫—Ç–æ–≤ 1‚Äì7, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç."""
    if not digest:
        return ""
    lines = []
    for line in digest.splitlines():
        m = re.match(r"^([1-7]Ô∏è‚É£)\s*(.*)$", line.strip())
        if not m:
            continue
        tag, rest = m.groups()
        if ":" in rest:
            head, tail = rest.split(":", 1)
            tail = tail.strip()
            if not tail.startswith(SECTION_EMOJI.get(tag, "")):
                tail = f"{SECTION_EMOJI.get(tag, '')} {tail}".strip()
            lines.append(f"{tag} {head.strip()}: {tail}")
        else:
            lines.append(f"{tag} {SECTION_EMOJI.get(tag,'')} {rest}".strip())
    return "\n\n".join(lines).strip()

def rebuild_lines_with_market_data(digest: str, market_data: dict | None) -> str:
    """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å –≤ –ø—É–Ω–∫—Ç–∞—Ö 2 –∏ 3 ‚Äî —Å—Ç—Ä–æ–∏–º –∏—Ö –∏–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
    if not market_data or not digest:
        return digest

    def _safe_val(name, fmt_val):
        if name not in market_data:
            return None
        v, c = market_data[name]
        ranges = {
            "sp500": (2000, 8000), "nasdaq": (5000, 25000),
            "dxy": (80, 120), "gold": (1000, 3000), "oil": (20, 150), "treasury": (0, 10)
        }
        lo, hi = ranges.get(name, (-1e9, 1e9))
        if not (lo <= v <= hi):
            return None
        return fmt_val(v) + f"({c:+.1f}%)"

    sp = _safe_val("sp500", lambda v: f"S&P500 ${v:.0f}")
    nd = _safe_val("nasdaq", lambda v: f"Nasdaq ${v:.0f}")
    au = _safe_val("gold",  lambda v: f"–ó–æ–ª–æ—Ç–æ ${v:.0f}")
    oi = _safe_val("oil",   lambda v: f"–ù–µ—Ñ—Ç—å ${v:.0f}")
    dx = _safe_val("dxy",   lambda v: f"DXY {v:.1f}")
    tn = _safe_val("treasury", lambda v: f"10Y {v:.1f}%")

    line2_parts = [p for p in (sp, nd, oi) if p]
    line3_parts = [p for p in (tn, dx, au, oi) if p]

    new_lines = []
    for line in digest.splitlines():
        if line.startswith("2Ô∏è‚É£"):
            txt = " ¬∑ ".join(line2_parts) if line2_parts else ""
            new_lines.append(f"2Ô∏è‚É£ –ò—Ç–æ–≥–∏ —Ç–æ—Ä–≥–æ–≤: {txt}".strip())
        elif line.startswith("3Ô∏è‚É£"):
            txt = " ¬∑ ".join(line3_parts) if line3_parts else ""
            new_lines.append(f"3Ô∏è‚É£ –¢—Ä–µ–∂–µ—Ä–∏—Å, DXY, –∑–æ–ª–æ—Ç–æ, –Ω–µ—Ñ—Ç—å: {txt}".strip())
        else:
            new_lines.append(line)
    return "\n\n".join(new_lines).strip()

def build_global_mood_line(market_data: dict | None) -> str:
    """
    –î–µ–ª–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É '1Ô∏è‚É£ –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Ä—ã–Ω–∫–∏: <—ç–º–æ–¥–∑–∏> ...'
    S&P500/Nasdaq ‚Äî –ø–æ–∑–∏—Ç–∏–≤, DXY/10Y ‚Äî –Ω–µ–≥–∞—Ç–∏–≤ –¥–ª—è —Ä–∏—Å–∫–∞.
    """
    if not market_data:
        return "1Ô∏è‚É£ –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Ä—ã–Ω–∫–∏: ‚ûñ –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Ñ–æ–Ω, —è–≤–Ω–æ–≥–æ –¥—Ä–∞–π–≤–µ—Ä–∞ –Ω–µ—Ç."

    up = 0.0
    down = 0.0

    def _add(name, weight=1.0, invert=False):
        nonlocal up, down
        if name in market_data:
            _, chg = market_data[name]
            chg = -chg if invert else chg
            if chg >= 0.05:
                up += weight * chg
            elif chg <= -0.05:
                down += weight * abs(chg)

    _add("sp500", 1.0)
    _add("nasdaq", 1.0)
    _add("dxy", 0.7, invert=True)
    _add("treasury", 0.7, invert=True)

    score = up - down
    if score > 0.3:
        emoji, phrase = "üìà", "–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π —Ç–æ–Ω –Ω–∞ –æ–∂–∏–¥–∞–Ω–∏—è—Ö —Å–ø—Ä–æ—Å–∞ –Ω–∞ —Ä–∏—Å–∫."
    elif score < -0.3:
        emoji, phrase = "üìâ", "–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π —Ñ–æ–Ω –∏–∑-–∑–∞ —Å–∏–ª—å–Ω–æ–≥–æ –¥–æ–ª–ª–∞—Ä–∞ –∏ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π."
    else:
        emoji, phrase = "‚ûñ", "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Ä—ã–Ω–æ–∫ –±–µ–∑ —è–≤–Ω–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞."
    return f"1Ô∏è‚É£ –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Ä—ã–Ω–∫–∏: {emoji} {phrase}"

def normalize_sections_spacing(text: str) -> str:
    """–ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É –ø—É–Ω–∫—Ç–∞–º–∏, –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–µ –¥–≤–æ–µ—Ç–æ—á–∏—è."""
    fixed = []
    for line in text.splitlines():
        line = re.sub(r"\s*:\s*", ": ", line, count=1)
        fixed.append(line.strip())
    return "\n\n".join([l for l in fixed if l])

def enforce_len_budget(header: str, body: str, tail: str, max_len: int) -> str:
    """
    –°–Ω–∞—á–∞–ª–∞ –º—è–≥–∫–æ —É–∫–æ—Ä–∞—á–∏–≤–∞–µ–º —Å–∞–º—ã–µ –¥–ª–∏–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ (‚âà180‚Üí‚âà160‚Üí‚âà100),
    –ø–æ—Ç–æ–º ‚Äî –µ—Å–ª–∏ –≤—Å—ë –µ—â—ë –¥–ª–∏–Ω–Ω–æ ‚Äî —É–±–∏—Ä–∞–µ–º –Ω–∞–∏–º–µ–Ω–µ–µ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã: 7Ô∏è‚É£‚Üí6Ô∏è‚É£‚Üí5Ô∏è‚É£‚Üí4Ô∏è‚É£.
    """
    parts = body.split("\n\n")

    def total_len(h, items, t):
        return len(h) + 2 + len("\n\n".join(items)) + 2 + len(t)

    # –º—è–≥–∫–∞—è —É—Å–∞–¥–∫–∞
    trimmed = []
    for s in parts:
        if len(s) > 180:
            cut = s[:175]
            last = max(cut.rfind(")"), cut.rfind("%"), cut.rfind(" "), cut.rfind("¬∑"))
            s = (cut[:last].rstrip() if last > 120 else cut.rstrip()) + "‚Ä¶"
        elif len(s) > 160:
            s = s[:160].rstrip() + "‚Ä¶"
        trimmed.append(s)
    parts = trimmed

    # –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ ‚Äî —É–¥–∞–ª—è–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É –¥–ª—è CEO
    drop_order = ["7Ô∏è‚É£","6Ô∏è‚É£","5Ô∏è‚É£","4Ô∏è‚É£"]
    while total_len(header, parts, tail) > max_len and parts:
        idx = max(range(len(parts)), key=lambda i: len(parts[i]))
        if len(parts[idx]) > 100:
            parts[idx] = parts[idx][:100].rstrip() + "‚Ä¶"
        if total_len(header, parts, tail) > max_len:
            found = next((i for i, s in enumerate(parts) if s[:2] in drop_order), None)
            if found is not None:
                parts.pop(found)
            else:
                parts.pop()

    return f"{header}\n\n" + "\n\n".join(parts) + f"\n\n{tail}"

# ================== LLM DIGEST (—á–µ—Ä–Ω–æ–≤–∏–∫ –¥–ª—è 7 —Å—Ç—Ä–æ–∫) ==================
async def ai_format_morning_digest_compact_final(news_list, market_data, crypto_data):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ¬´—á–µ—Ä–Ω–æ–≤–∏–∫¬ª –Ω–∞ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—É–Ω–∫—Ç–∞ 1..7, –±–µ–∑ markdown.
    –ü–æ—Ç–æ–º –ø–µ—Ä–µ–∑–∞–ø–∏—à–µ–º 1/2/3 —Ü–∏—Ñ—Ä–∞–º–∏ –∏ –ø—Ä–æ—Å—Ç–∞–≤–∏–º —ç–º–æ–¥–∑–∏.
    """
    client = openai.AsyncOpenAI(api_key=OPENAI_API_KEY)

    real_data = ""
    if market_data:
        if "sp500" in market_data:
            v, c = market_data["sp500"]; real_data += f"S&P500 ${v:.0f}({c:+.1f}%), "
        if "nasdaq" in market_data:
            v, c = market_data["nasdaq"]; real_data += f"Nasdaq ${v:.0f}({c:+.1f}%), "
        if "gold" in market_data:
            v, c = market_data["gold"]; real_data += f"–ó–æ–ª–æ—Ç–æ ${v:.0f}({c:+.1f}%), "
        if "oil" in market_data:
            v, c = market_data["oil"]; real_data += f"–ù–µ—Ñ—Ç—å ${v:.0f}({c:+.1f}%), "
        if "dxy" in market_data:
            v, c = market_data["dxy"]; real_data += f"DXY {v:.1f}({c:+.1f}%), "
        if "treasury" in market_data:
            v, c = market_data["treasury"]; real_data += f"10Y {v:.1f}%({c:+.1f}%)"

    news_titles = "\n".join([f"- {n['title']}" for n in news_list[:8]])

    prompt = f"""
–°–¥–µ–ª–∞–π –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π ¬´CEO morning brief¬ª –Ω–∞ —Ä—É—Å—Å–∫–æ–º (–¥–æ 900 —Å–∏–º–≤–æ–ª–æ–≤ –≤—Å–µ–≥–æ).
–°—Ç—Ä–æ–≥–æ 7 —Å—Ç—Ä–æ–∫, –∫–∞–∂–¥–∞—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –Ω–æ–º–µ—Ä–∞ 1Ô∏è‚É£..7Ô∏è‚É£ –∏ –ë–ï–ó –¥–æ–ø.—Å—Ç—Ä–æ–∫:
1Ô∏è‚É£ –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Ä—ã–Ω–∫–∏ ‚Äî –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ (–±–µ–∑ —Ü–∏—Ñ—Ä).
2Ô∏è‚É£ –ò—Ç–æ–≥–∏ —Ç–æ—Ä–≥–æ–≤ ‚Äî –¢–û–õ–¨–ö–û –∏–∑ –Ω–∞–±–æ—Ä–∞: {real_data}
3Ô∏è‚É£ –¢—Ä–µ–∂–µ—Ä–∏—Å/DXY/–∑–æ–ª–æ—Ç–æ/–Ω–µ—Ñ—Ç—å ‚Äî –¢–û–õ–¨–ö–û –∏–∑ –Ω–∞–±–æ—Ä–∞: {real_data}
4Ô∏è‚É£ –ú–æ–Ω–µ—Ç–∞—Ä–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ ‚Äî –æ–¥–Ω–æ –∫–æ—Ä–æ—Ç–∫–æ–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ.
5Ô∏è‚É£ –ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ ‚Äî –æ–¥–∏–Ω —Ñ–∞–∫—Ç (–∫—Ä—É–ø–Ω—ã–µ —ç–º–∏—Ç–µ–Ω—Ç—ã/IPO/M&A/–≥–∞–π–¥).
6Ô∏è‚É£ –ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã ‚Äî –æ–¥–∏–Ω —Ñ–∞–∫—Ç (—Ä–µ–≥—É–ª—è—Ç–æ—Ä—ã/–ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å/–∏–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏).
7Ô∏è‚É£ –ì–µ–æ–ø–æ–ª–∏—Ç–∏–∫–∞ ‚Äî –æ–¥–∏–Ω —Ñ–∞–∫—Ç —Å —Ä—ã–Ω–æ—á–Ω–æ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å—é.

–¢–æ–Ω: Bloomberg/NYT/Reuters. –ë–µ–∑ markdown, –±–µ–∑ –∂–∏—Ä–Ω–æ–≥–æ, –±–µ–∑ —ç–º–æ–¥–∑–∏.
–û–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞ –Ω–∞ –ø—É–Ω–∫—Ç. –ë–µ–∑ –≤—Ç–æ—Ä—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.

–§–∞–∫—Ç-–±–∞–∑–∞ (–∏—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —ç—Ç–æ):
{news_titles}
"""

    resp = await client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "–¢—ã ‚Äî —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π —Ä–µ–¥–∞–∫—Ç–æ—Ä –¥–ª—è CEO. –°—Ç—Ä–æ–≥–æ, –∫—Ä–∞—Ç–∫–æ, —Ñ–∞–∫—Ç–æ–ª–æ–≥–∏—á–Ω–æ."},
            {"role": "user", "content": prompt},
        ],
        max_tokens=420,
        temperature=0.2,
    )
    return (resp.choices[0].message.content or "").strip()

# ================== MAIN ==================
async def send_morning_digest():
    print("üöÄ –ó–∞–ø—É—Å–∫ —É—Ç—Ä–µ–Ω–Ω–µ–π —Å–≤–æ–¥–∫–∏...")

    # 1) —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ —É—Ç—Ä–µ–Ω–Ω–µ–µ –æ–∫–Ω–æ
    print("üì∞ –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ RSS (—Ç–æ–ª—å–∫–æ —Å–≤–µ–∂–∏–µ)‚Ä¶")
    pool = get_feed_news(CRYPTO_FEEDS + FINANCE_FEEDS, NEWS_COUNT)
    if not pool:
        print("‚ö†Ô∏è –ù–µ—Ç —Å–≤–µ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –æ–∫–Ω–µ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏")
        return

    news_list = filter_by_importance(pool, NEWS_COUNT)
    print(f"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ {len(news_list)} –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π (‚â§ {FRESHNESS_HOURS_MORNING}—á)")

    # 2) —Ä—ã–Ω–∫–∏/–∫—Ä–∏–ø—Ç–∞
    market_data = await get_market_data()
    crypto_data = await get_crypto_data()

    # 3) —Ç–µ–∫—Å—Ç —Å–≤–æ–¥–∫–∏ (—á–µ—Ä–Ω–æ–≤–∏–∫ –æ—Ç LLM)
    print("ü§ñ –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—É—é —Å–≤–æ–¥–∫—É‚Ä¶")
    digest_raw = await ai_format_morning_digest_compact_final(news_list, market_data, crypto_data)

    # === –ü–û–°–¢-–û–ë–†–ê–ë–û–¢–ö–ê –°–¢–ò–õ–Ø ===
    digest = sanitize_markdown(digest_raw)                      # —É–±–∏—Ä–∞–µ–º ** –∏ –ø—Ä.
    digest = enforce_seven_compact_lines(digest)                # —Å—Ç—Ä–æ–≥–æ 7 —Å—Ç—Ä–æ–∫ / 1 –Ω–∞ –ø—É–Ω–∫—Ç
    digest = rebuild_lines_with_market_data(digest, market_data)# 2 –∏ 3 —Å—Ç—Ä–æ–≥–æ –∏–∑ market_data
    digest = decorate_digest_with_emojis(digest)                # —ç–º–æ–¥–∑–∏ –ø–æ–¥ –∫–∞–∂–¥—ã–π –ø—É–Ω–∫—Ç

    # mood-line –¥–ª—è 1Ô∏è‚É£
    mood_line = build_global_mood_line(market_data)
    lines = digest.split("\n\n")
    if lines and lines[0].startswith("1Ô∏è‚É£"):
        lines[0] = mood_line
    digest = "\n\n".join(lines)
    digest = normalize_sections_spacing(digest)

    # 4) —à–∞–ø–∫–∞/–ø–æ–¥–ø–∏—Å—å
    now_local = datetime.now(LOCAL_TZ)
    header = f"üåÖ –£—Ç—Ä–µ–Ω–Ω—è—è —Å–≤–æ–¥–∫–∞ ‚Äî {now_local:%d.%m.%Y}"
    tail = SIGNATURE

    # 5) –∫—Ä–∏–ø—Ç–æ-–±–ª–æ–∫ ‚Äî –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–π
    body = digest
    if crypto_data:
        crypto_lines = ["üíé –ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã (–¢–û–ü-5)"]
        if "bitcoin" in crypto_data:
            p = crypto_data["bitcoin"]["usd"]; c = crypto_data["bitcoin"]["usd_24h_change"]
            crypto_lines.append(f"BTC ${p:,.0f}({c:+.1f}%)")
        if "ethereum" in crypto_data:
            p = crypto_data["ethereum"]["usd"]; c = crypto_data["ethereum"]["usd_24h_change"]
            crypto_lines.append(f"ETH ${p:,.0f}({c:+.1f}%)")
        if "binancecoin" in crypto_data:
            p = crypto_data["binancecoin"]["usd"]; c = crypto_data["binancecoin"]["usd_24h_change"]
            crypto_lines.append(f"BNB ${p:.0f}({c:+.1f}%)")
        if "ripple" in crypto_data:
            p = crypto_data["ripple"]["usd"]; c = crypto_data["ripple"]["usd_24h_change"]
            crypto_lines.append(f"XRP ${p:.2f}({c:+.1f}%)")
        if "solana" in crypto_data:
            p = crypto_data["solana"]["usd"]; c = crypto_data["solana"]["usd_24h_change"]
            crypto_lines.append(f"SOL ${p:.0f}({c:+.1f}%)")
        body = body + "\n\n" + "\n".join(crypto_lines)

    # 6) –∂—ë—Å—Ç–∫–∏–π –ª–∏–º–∏—Ç –∏ –∏—Ç–æ–≥–æ–≤—ã–π —Ç–µ–∫—Å—Ç
    full_post = enforce_len_budget(header, body, tail, MAX_CAPTION)
    print(f"\n================= PREVIEW (console only) =================\n{full_post}\n==========================================================")
    print(f"üßÆ –î–ª–∏–Ω–∞ –ø–æ—Å—Ç–∞: {len(full_post)} —Å–∏–º–≤–æ–ª–æ–≤")

    # 7) –æ—Ç–ø—Ä–∞–≤–∫–∞ / –∫–æ–Ω—Å–æ–ª—å
    if SEND_TO_TELEGRAM:
        print("üì§ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Telegram‚Ä¶")
        image = await get_morning_image()
        try:
            bot = Bot(token=TELEGRAM_TOKEN)
            if image:
                await bot.send_photo(
                    chat_id=TELEGRAM_CHANNEL_RU,
                    photo=image,
                    caption=full_post,
                    parse_mode=None,  # —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç
                )
            else:
                await bot.send_message(
                    chat_id=TELEGRAM_CHANNEL_RU,
                    text=full_post,
                    parse_mode=None,
                )
            print("‚úÖ –ü–æ—Å—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ Telegram!")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {e}")
    else:
        print("üß™ SEND_TO_TELEGRAM=0 ‚Äî –æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram –æ—Ç–∫–ª—é—á–µ–Ω–∞, –≤—ã–≤–æ–¥ —Ç–æ–ª—å–∫–æ –≤ –∫–æ–Ω—Å–æ–ª—å.")

    # 8) –∫—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"‚Ä¢ –ù–æ–≤–æ—Å—Ç–µ–π: {len(news_list)}")
    print(f"‚Ä¢ –°–∏–º–≤–æ–ª–æ–≤: {len(full_post)}")
    print(f"‚Ä¢ –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {'‚úÖ' if market_data else '‚ùå'}")
    print(f"‚Ä¢ –ö—Ä–∏–ø—Ç–æ-–¥–∞–Ω–Ω—ã–µ: {'‚úÖ' if crypto_data else '‚ùå'}")
    print(f"‚Ä¢ –û–∫–Ω–æ —Å–≤–µ–∂–µ—Å—Ç–∏: {FRESHNESS_HOURS_MORNING} —á")
    print(f"‚Ä¢ –ò—Å—Ç–æ—á–Ω–∏–∫ —Ä—ã–Ω–∫–æ–≤: {MARKET_SOURCE_MODE}")
    print(f"‚Ä¢ –†–µ–∂–∏–º –æ—Ç–ø—Ä–∞–≤–∫–∏: {'Telegram' if SEND_TO_TELEGRAM else 'Console'}")

if __name__ == "__main__":
    asyncio.run(send_morning_digest())
